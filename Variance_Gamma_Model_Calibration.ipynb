{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0b4504a4",
      "metadata": {
        "id": "0b4504a4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import metrics\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VG-Cos Method\n",
        "$$C = e^{-rt}\\sum_{k=0}^{N-1} \\operatorname{Re} \\left\\{ e^{iu\\mu t}\\cdot \\left(1- iu\\theta\\nu + \\frac{\\sigma^2\\nu u^2}{2}\\right)^{\\frac{t}{\\nu}} \\cdot e^{iux} \\cdot e^{ik\\frac{a}{b-a}} \\right\\} \\cdot \\left(  \\frac{2}{b-a} K\\left[\\chi_{k}(0, b)-\\varphi_{k}(0, b)\\right] \\right)$$\n",
        "\n",
        "\\begin{align}\n",
        " \\psi_{k}(c, d) =  \\begin{cases}{\\left[\\sin \\left(k \\pi \\frac{d-a}{b-a}\\right)-\\sin \\left(k \\pi \\frac{c-a}{b-a}\\right)\\right] \\frac{b-a}{k \\pi}} & k \\neq 0 \\\\ (d-c) & k=0 .\\end{cases}\n",
        " \\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "\\chi_{k}(c, d) = \\frac{1}{1+\\left(\\frac{k \\pi}{b-a}\\right)^{2}}\\left[\\cos \\left(k \\pi \\frac{d-a}{b-a}\\right) e^{d}-\\cos \\left(k \\pi \\frac{c-a}{b-a}\\right) e^{c}\\right. \\left.+\\frac{k \\pi}{b-a} \\sin \\left(k \\pi \\frac{d-a}{b-a}\\right) e^{d}-\\frac{k \\pi}{b-a} \\sin \\left(k \\pi \\frac{c-a}{b-a}\\right) e^{c}\\right]\n",
        "\\end{align}"
      ],
      "metadata": {
        "id": "go_zlNhaw9fK"
      },
      "id": "go_zlNhaw9fK"
    },
    {
      "cell_type": "code",
      "source": [
        "def CHI(a,b,c,d,k):\n",
        "    A = (k*np.pi)/(b-a)\n",
        "    val = (1/(1+A**2))*( np.cos(A*(d-a))*np.exp(d)- np.cos(A*(c-a))*np.exp(c) + A*np.sin(A*(d-a))*np.exp(d) - A*np.sin(A*(c-a))*np.exp(c)  )\n",
        "    return val\n",
        "\n",
        "def PSI(a,b,c,d,k):\n",
        "    A = (k*np.pi)/(b-a)\n",
        "    if k == 0:\n",
        "        val = d-c \n",
        "    else:\n",
        "        val = A**(-1)*( np.sin(A*(d-a)) - np.sin(A*(c-a)) )\n",
        "    return val\n",
        "\n",
        "def V_call(K,a,b,k): #V_k for vanilla call options\n",
        "    val = (2/(b-a))*K*(CHI(a,b,0,b,k)-PSI(a,b,0,b,k))\n",
        "    return val\n",
        "\n",
        "def VG_CHARAC(S0,K,T,r,a,b,sig,theta,nu,k):\n",
        "    i = complex(0,1)\n",
        "    x = np.log(S0/K)\n",
        "    u = (k*np.pi)/(b-a)\n",
        "    mu = r + ( 1/nu*(np.log(1-theta*nu-0.5*sig**2*nu)) )\n",
        "    val = np.exp(i*u*x) * np.exp(i*u*mu*T) * (1-i*u*theta*nu+0.5*sig**2*nu*u**2)**(-T/nu) #VG characteristic function\n",
        "    return val\n",
        "\n",
        "def VG_EuroCall(S0,K,T,r,sig,theta,nu,N): #pricing formula\n",
        "    i = complex(0,1)\n",
        "    L = 10\n",
        "    c1 = (r+theta)*T\n",
        "    c2 = (sig**2 + nu*theta**2)*T\n",
        "    c4 = 3*(sig**4*nu + 2*theta**4*nu**3 + 4*sig**2*theta**2*nu**2)*T\n",
        "    a = c1 - L*np.sqrt(c2+ np.sqrt(c4)) \n",
        "    b = c1 + L*np.sqrt(c2+ np.sqrt(c4)) \n",
        "    P = []\n",
        "    for k in range(N):\n",
        "        u = (k*np.pi)/(b-a)\n",
        "        val = (VG_CHARAC(S0,K,T,r,a,b,sig,theta,nu,k) * np.exp(-i*a*u)).real * V_call(K,a,b,k) \n",
        "        P.append(val)\n",
        "    P[0] = 0.5*P[0] #first term is weighted by half\n",
        "    val = (sum(P))*np.exp(-r*T)\n",
        "    return val"
      ],
      "metadata": {
        "id": "bqy9P-Qtw7K7"
      },
      "id": "bqy9P-Qtw7K7",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistic Function"
      ],
      "metadata": {
        "id": "X8FVd7mbDrqI"
      },
      "id": "X8FVd7mbDrqI"
    },
    {
      "cell_type": "code",
      "source": [
        "def STAT(L):\n",
        "    \"\"\"\n",
        "    Statistic function\n",
        "    Inputs: List/array L\n",
        "    Outputs: max, min, mean\n",
        "    \"\"\"\n",
        "    print(\"max = \"+str(np.max(L)) )\n",
        "    print(\"min = \"+str(np.min(L)) )\n",
        "    print(\"mean = \"+str(np.sum(L)/len(L)) )"
      ],
      "metadata": {
        "id": "xIGO9aNADx7N"
      },
      "id": "xIGO9aNADx7N",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Range for strikes and maturity times\n",
        "The NN is trained on $5$ stikes and $4$ maurities, thus resulting into a vector of $20$ prices"
      ],
      "metadata": {
        "id": "-N1lOz86x59J"
      },
      "id": "-N1lOz86x59J"
    },
    {
      "cell_type": "code",
      "source": [
        "S0 = 1.\n",
        "K = np.array([0.8,0.9,1.0,1.1, 1.2], dtype=np.float32) #list of strikes\n",
        "T = np.array([.5,.75,1.,1.25], dtype=np.float32) #list of maturities"
      ],
      "metadata": {
        "id": "IOpK2iSNxmP2"
      },
      "id": "IOpK2iSNxmP2",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r,sig,theta,nu = 0.1,0.2,-0.14,0.2\n",
        "\n",
        "for i in range(len(T)):\n",
        "    print(VG_EuroCall(S0,K,T[i],r,sig,theta,nu,256)) #example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJTc-L6yuji",
        "outputId": "47c7405f-6668-4e9b-b079-ebaacda500dc"
      },
      "id": "JaJTc-L6yuji",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.24244133 0.15607768 0.08371659 0.03516488 0.01227804]\n",
            "[0.2629346  0.18055701 0.1106998  0.05920353 0.02778986]\n",
            "[0.28267395 0.2034122  0.13530204 0.0823326  0.04587126]\n",
            "[0.30167663 0.22500885 0.15832527 0.10457461 0.0648732 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "480b9b0c",
      "metadata": {
        "id": "480b9b0c"
      },
      "source": [
        "# Pricing Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4bcedea3",
      "metadata": {
        "id": "4bcedea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5908ef8b-dd74-458f-c69b-2bea4fb23cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                80        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,068\n",
            "Trainable params: 8,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VG_pricer=Sequential([\n",
        "    Dense(16, activation =\"relu\", input_shape=(4,)),\n",
        "    Dense(64, activation =\"relu\"),\n",
        "    Dense(64, activation =\"relu\"),\n",
        "    Dense(32, activation =\"relu\"),\n",
        "    Dense(len(K)*len(T)) ])\n",
        "\n",
        "lr = 0.02\n",
        "loss = \"mse\"\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
        "optimizer = tf.keras.optimizers.SGD( learning_rate = lr, momentum= 0.8, nesterov=False)\n",
        "\n",
        "VG_pricer.compile(loss = loss, optimizer = optimizer,metrics = ['accuracy'])\n",
        "VG_pricer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dced12b",
      "metadata": {
        "id": "0dced12b"
      },
      "source": [
        "#Training\n",
        "* For each training epoch a new data set is created. This is time cosuming, but it avoids over fitting.\n",
        "* use random values of $\\{r,\\sigma,\\theta,\\nu\\}$ for each set, such that;\n",
        "\\begin{align}\n",
        "r &= [0,0.2]\\\\\n",
        "\\sigma &= [0.0,0.2]\\\\\n",
        "\\theta &= [-0.3,0.05]\\\\\n",
        "\\nu &= [0.0,0.7]\\\\\n",
        "\\end{align}\n",
        "\n",
        "#Since we alrady have a pre-trained model we skip the training process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "64314830",
      "metadata": {
        "id": "64314830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0513b495-1db2-4871-ba40-e07d733b3023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "half way point\n",
            "16/16 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.4893 - mean_squared_error: 0.0052 \n"
          ]
        }
      ],
      "source": [
        "Training_epochs = 100 #Training epochs\n",
        "Data_size = 1024 #Training Data Size per epoch\n",
        "\n",
        "Y_mat = np.zeros((Data_size, len(T),len(K))) \n",
        "\n",
        "for n in range(Training_epochs):\n",
        "    r = np.random.uniform(low = 0.0, high = 0.2, size = (Data_size,1) ) \n",
        "    sig = np.random.uniform(low = 0.0, high = 0.2,size = (Data_size,1) )\n",
        "    theta = np.random.uniform(low = -0.3, high = 0.05,size = (Data_size,1) )\n",
        "    nu = np.random.uniform(low = 0.0, high = 0.7,size = (Data_size,1) )\n",
        "    X=np.concatenate([r,sig,theta,nu],axis=1) #Inputs\n",
        "\n",
        "    for b in range(Data_size):\n",
        "        for i in range(len(T)):\n",
        "            Y_mat[b,i,:]= VG_EuroCall(S0,K,T[i],r[b],sig[b],theta[b],nu[b],256)\n",
        "    Y = Y_mat.reshape((-1,len(K)*len(T))) #Targets. 20 option prices for each vector [r,sig,theta,nu]\n",
        "    \n",
        "    if n%5==0:\n",
        "        lr = lr*0.95  #Decreases the learnig rate after every 5 epochs\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
        "        #optimizer = tf.keras.optimizers.SGD( learning_rate = lr, momentum= 0.8, nesterov=False)\n",
        "        VG_pricer.compile(loss = loss, optimizer = optimizer,metrics=['accuracy'])\n",
        "\n",
        "    if n == int(Training_epochs/2): #Training marker for half the epochs\n",
        "         print(\"half way point\")\n",
        "\n",
        "    history = VG_pricer.fit(X,Y, epochs = 1, batch_size = 64) #NN Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7752b91f",
      "metadata": {
        "id": "7752b91f"
      },
      "source": [
        "#Evaluation on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1c297e0c",
      "metadata": {
        "id": "1c297e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b603c7-9308-4d58-fd15-acee4c73a1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 1.7411e-04 - accuracy: 0.9688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00017411098815500736, 0.96875]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "val_data_size = 1024\n",
        "\n",
        "r_val = np.random.uniform(low = 0, high = 0.2, size = (val_data_size,1) )\n",
        "sig_val = np.random.uniform(low = 0.0, high = 0.25,size = (val_data_size,1) )\n",
        "theta_val = np.random.uniform(low =-0.3, high = 0.06,size = (val_data_size,1) )\n",
        "nu_val = np.random.uniform(low = 0.0, high = 0.8,size = (val_data_size,1) )\n",
        "\n",
        "X_val = np.concatenate([r_val,sig_val,theta_val,nu_val],axis=1) #inputs\n",
        "Y_mat_val = np.zeros((val_data_size, len(T), len(K)))\n",
        "\n",
        "for b in range(val_data_size):\n",
        "    for i in range(len(T)):\n",
        "        Y_mat_val[b,i,:] = VG_EuroCall(S0,K,T[i],r_val[b],sig_val[b],theta_val[b],nu_val[b],256)\n",
        "        \n",
        "Y_val = Y_mat_val.reshape((-1,len(K)*len(T))) #Target. 20 0ption prices\n",
        "\n",
        "VG_pricer.evaluate(X_val, Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b21948d",
      "metadata": {
        "id": "6b21948d"
      },
      "source": [
        "#Comparing predictions against actual prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "36e23d92",
      "metadata": {
        "id": "36e23d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e869043-98a8-4ca9-e802-0cf8c3eeb8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1281768240942006, 0.13960152707770448, -0.21310066489295615, 0.6484562928471561] parameters \n",
            "\n",
            "\n",
            "[[0.2595465  0.16976735 0.09282494 0.03259636 0.00699619]\n",
            " [0.28322622 0.20045216 0.12470405 0.06717475 0.02347637]\n",
            " [0.3071906  0.22846025 0.1562967  0.09206533 0.04594036]\n",
            " [0.33100128 0.2546702  0.18331784 0.12381677 0.07279095]] Prediction \n",
            "\n",
            " [[0.25619286 0.1709948  0.09444167 0.03380528 0.00380239]\n",
            " [0.28166196 0.20044391 0.12714639 0.06618325 0.02321608]\n",
            " [0.30579242 0.22780922 0.15695129 0.0962722  0.0490859 ]\n",
            " [0.32877883 0.25359112 0.18480116 0.12467662 0.07546259]] Actual\n"
          ]
        }
      ],
      "source": [
        "r = np.random.uniform(low = 0, high = 0.2)\n",
        "sig = np.random.uniform(low = 0.0, high = 0.2)\n",
        "theta = np.random.uniform(low =-0.3, high = 0.05 )\n",
        "nu = np.random.uniform(low = 0.0, high = 0.7 )\n",
        "\n",
        "parameters = [r,sig,theta,nu]\n",
        "\n",
        "y_pred = VG_pricer.predict([parameters]) #Using the pricing NN\n",
        "y_act = np.zeros((len(T),len(K)))\n",
        "\n",
        "for i in range(len(T)):\n",
        "        y_act[i,:] = VG_EuroCall(S0,K,T[i],r,sig,theta,nu,256)\n",
        "y_pred = np.array(tf.reshape(y_pred, (4,5)))\n",
        "\n",
        "print(parameters,\"parameters\",\"\\n\"*2)\n",
        "print(y_pred,\"Prediction\",2*\"\\n\",y_act,\"Actual\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1826be",
      "metadata": {
        "id": "0d1826be"
      },
      "source": [
        "#Relative pricing error for 20 options as a percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "462e03c2",
      "metadata": {
        "id": "462e03c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adedb67d-d0ea-46b7-dedd-6fc3ce442659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.30902379e+00 7.17830792e-01 1.71187558e+00 3.57610610e+00\n",
            "  8.39945038e+01]\n",
            " [5.55369391e-01 4.11848051e-03 1.92089210e+00 1.49811465e+00\n",
            "  1.12117776e+00]\n",
            " [4.57230415e-01 2.85779360e-01 4.17067675e-01 4.36976974e+00\n",
            "  6.40823181e+00]\n",
            " [6.75970702e-01 4.25520613e-01 8.02657938e-01 6.89663497e-01\n",
            "  3.54035546e+00]] \n",
            "\n",
            "max = 83.99450375172829\n",
            "min = 0.004118480506689074\n",
            "mean = 5.724062980862763\n"
          ]
        }
      ],
      "source": [
        "L = (np.abs(y_pred-y_act)/y_act)*100\n",
        "print(L,\"\\n\")\n",
        "L = np.array( tf.reshape(L,(1,20)) )[0]\n",
        "STAT(L)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc6ac76",
      "metadata": {
        "id": "dbc6ac76"
      },
      "source": [
        "# Saving the Pricng NN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#VG_pricer.save('Variance_Gamma_Pricing_NN.h5')"
      ],
      "metadata": {
        "id": "XenZ0jroB-bD"
      },
      "id": "XenZ0jroB-bD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For calibration, we load a pre-trained model"
      ],
      "metadata": {
        "id": "k-WVcXra3O86"
      },
      "id": "k-WVcXra3O86"
    },
    {
      "cell_type": "code",
      "source": [
        "VG_pricer = load_model('Variance_Gamma_Pricing_NN_Weights.h5') "
      ],
      "metadata": {
        "id": "y0MxJzyY3XL2"
      },
      "id": "y0MxJzyY3XL2",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S0 = 1.\n",
        "K = np.array([0.8,0.9,1.0,1.1, 1.2], dtype=np.float32)\n",
        "T = np.array([.5,.75,1.,1.25], dtype=np.float32)"
      ],
      "metadata": {
        "id": "ur3nPFZz7v3y"
      },
      "id": "ur3nPFZz7v3y",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b8c3320e",
      "metadata": {
        "id": "b8c3320e"
      },
      "source": [
        "# Constructing the calibrator\n",
        "* To make the calibrator more stable the actiation function used on the first hidden layer is custom made to be within the range of each parameter of interest, and this is achieved through modifying the sigmoid function to produce outputs in the range $[a,b]$ rather than its original range of $[0,1]$. In the modified sigmoid, $c$ marks where the function is centered and $d$ controls the slope of the graph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_sigmoid(x,a = 0.0,b = 1.0,c = 0.0,d = 1.0): #Modified sigmoid\n",
        "    return (b-a)*tf.math.sigmoid( (x-c)/d ) + a\n",
        "\n",
        "@tf.function \n",
        "def Custom_Activation(x): #custom activation function\n",
        "    return tf.stack([modified_sigmoid(x[...,0],0.0,0.2,0.1,0.05), modified_sigmoid(x[...,1],0.0,0.2,0.1,0.05),\n",
        "                     modified_sigmoid(x[...,2],-0.3,0.05,-.1525,0.05), modified_sigmoid(x[...,3],0.0,0.7,.35,0.05) ], axis = 1)"
      ],
      "metadata": {
        "id": "Y-I_mBDIT7r9"
      },
      "id": "Y-I_mBDIT7r9",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The calibrator NN is set up in such a way that the parameters being trained are the weights from the first hidden layer, thus the bias from this layer is deactivated. Hidden layer after the first hidden layer are the same as in the pricing NN as they use weights obtained from it."
      ],
      "metadata": {
        "id": "gd0GxUjpWS7o"
      },
      "id": "gd0GxUjpWS7o"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "78dfa138",
      "metadata": {
        "id": "78dfa138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37784466-c640-4a54-97fc-b4c3353c8e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 4)                 4         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                1088      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,072\n",
            "Trainable params: 4\n",
            "Non-trainable params: 8,068\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VG_calibrator = Sequential([\n",
        "    Dense(4, input_dim= 1, use_bias=False , kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None),\n",
        "          activation = Custom_Activation),\n",
        "    Dense(16, activation =\"relu\"),\n",
        "    Dense(64, activation =\"relu\"),\n",
        "    Dense(64, activation =\"relu\"),\n",
        "    Dense(32, activation =\"relu\"),\n",
        "    Dense(len(K)*len(T))    ]) \n",
        "\n",
        "#setting and fixing the weights obtained from the pricing NN\n",
        "for i in range(1, len(VG_calibrator.layers)):\n",
        "    VG_calibrator.layers[i].set_weights(VG_pricer.layers[i-1].weights)\n",
        "    VG_calibrator.layers[i].trainable=False \n",
        "VG_calibrator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The calibrator NN takes the vector of $[1]$ as an input and learns the weights of the fist hidden layer by matching them to actual prices on the market, thus we create a set of 20 prices to represent the market observed prices"
      ],
      "metadata": {
        "id": "gYcqwgW2TEIR"
      },
      "id": "gYcqwgW2TEIR"
    },
    {
      "cell_type": "code",
      "source": [
        "r = np.random.uniform(low = 0, high = 0.2 )\n",
        "sig = np.random.uniform(low = 0.0, high = 0.2 )\n",
        "theta = np.random.uniform(low =-0.3, high = 0.05)\n",
        "nu = np.random.uniform(low = 0.0, high = 0.7)\n",
        "\n",
        "actual_parameters = np.array([[r,sig,theta,nu]])  #Paramerts to calibrate\n",
        "y_mrkt = VG_pricer(actual_parameters).numpy() #Represents market observed prices"
      ],
      "metadata": {
        "id": "rQJ-oELntNRn"
      },
      "id": "rQJ-oELntNRn",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The calibration may need to be run 2 or 3 times in order to improve the accuarcy of the model"
      ],
      "metadata": {
        "id": "qt4LQe3YBY_d"
      },
      "id": "qt4LQe3YBY_d"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "96e060fb",
      "metadata": {
        "id": "96e060fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4dc0df-7bae-47d5-9347-929e6d385093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " [[0.1543818  0.09993176 0.03845835 0.0475434 ]] Prediction\n",
            " [[0.15438092 0.09993025 0.03845837 0.04754457]] Actual\n"
          ]
        }
      ],
      "source": [
        "def scheduler(epoch, lr): #learning rate schedular\n",
        "      if epoch % 10==0:\n",
        "        return lr*0.95\n",
        "      else:\n",
        "        return lr \n",
        "    \n",
        "for _ in range(8): #training the calibrator\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "    VG_calibrator.compile(loss = \"mse\" , optimizer = optimizer,metrics = [\"accuracy\"])\n",
        "    callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "    history = VG_calibrator.fit(np.array([[1.]]), y_mrkt, epochs = 100, verbose = 0, callbacks = [callback])\n",
        "\n",
        "w = VG_calibrator.layers[0].weights[0].numpy() #exatracting the first layer weights\n",
        "pars_pred = Custom_Activation(w).numpy()  #passing the weight throughh the custom activation\n",
        "\n",
        "print(2*\"\\n\",pars_pred,\"Prediction\"\"\\n\",actual_parameters,\"Actual\") #Predicted vs actual parameters"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Variance_Gamma_Model_Calibration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}